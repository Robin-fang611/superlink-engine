# SuperLink Data Engine (SuperLink 数据引擎)

## 1. 运行环境 (Environment)
本项目基于 Python 开发，核心依赖库详见 `requirements.txt`。

**一键安装依赖：**
```bash
pip install -r requirements.txt
```

**启动网页控制台：**
```bash
streamlit run app.py
```

## 2. 核心功能 (Core Features)

### 🌐 网页管理控制台 (Web Console)
通过 `app.py` 启动的 Streamlit 界面，提供直观的操作体验：
- **实时任务启动**：支持单次搜索、批量模式和工厂模式。
- **数据即时预览**：无需打开 CSV，直接在网页查看抓取结果。
- **文件导出**：一键下载生成的 CSV 报表。
- **历史管理**：内置“历史与导出”选项卡，支持查看、下载和删除过往抓取的数据。
- **访问控制**：支持设置 `APP_PASSWORD` 进行简单的网页访问权限保护。

### 🚀 自动化工厂模式 (Automation Factory Mode) - [Option 6]
这是本系统的旗舰功能，旨在实现**无人值守的全天候数据挖掘**。

*   **运行逻辑**：
    *   用户选择目标板块（如物流、进口商等）或输入自定义关键词。
    *   系统自动加载内置的 **50+ 全球核心商业城市**（覆盖欧美主要港口与商业中心）。
    *   **深度挖掘**：对每个“关键词 + 城市”组合，自动抓取 **前 3 页** (Page 1-3) 的 Google 搜索结果。
    *   **智能控速**：内置随机延迟机制（翻页间隔 3-5s，城市间隔 10-15s），模拟真人操作以保护 API 账号。

*   **内置城市库**：
    *   **USA**: New York, Los Angeles, Chicago, Houston, Miami, Seattle, etc.
    *   **Europe**: London, Hamburg, Rotterdam, Antwerp, Berlin, Paris, etc.

*   **断点续传机制 (Checkpoint & Resume)**：
    *   系统会自动生成 `progress_log.json` 文件。
    *   每完成一个城市的搜索，立即记录进度。
    *   若程序中断（如网络故障或手动停止），下次运行会自动跳过已完成的城市，**绝不重复劳动**。

## 3. 数据结构 (Data Structure)
输出文件位于 `output/` 目录下，文件名格式为 `superlink_leads_YYYY.MM.DD.HH.MM.csv`。

**CSV 表头定义：**
| 字段名 (Header) | 说明 |
| :--- | :--- |
| **公司名称** | 目标企业名称 |
| **注册国家/城市** | 企业所在地 |
| **业务负责人** | 关键联系人姓名 (如有) |
| **公开电话** | 官方联系电话 |
| **公开邮箱** | **核心资产**，用于开发信 |
| **业务范围** | 产品或服务描述 |
| **来源URL** | 数据来源网页链接 |

## 4. 维护笔记 (Maintenance Notes)

### ✅ 已修复问题
*   **NoneType Crash Fix**: 修复了在去重 (`is_duplicate`) 和数据清洗过程中，因字段值为 `None` 导致的 `AttributeError: 'NoneType' object has no attribute 'strip'` 崩溃问题。
    *   **解决方案**: 在所有字段提取处强制执行 `str(val or "").strip()`，确保空值安全。
*   **即时落盘**: 实现了流式写入 (`f.flush() + os.fsync()`)，确保每一条数据在抓取后立即物理写入硬盘，防止程序意外终止导致数据丢失。

---
*Generated by SuperLink Dev Assistant*
