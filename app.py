import streamlit as st
import os
import sys
import time
import pandas as pd
import glob
import json
import threading
from datetime import datetime
from dotenv import load_dotenv

# Ensure core modules can be imported
sys.path.append(os.getcwd())

from core.searcher import Searcher
from core.processor import Processor
from core.automation import AutomationManager

# Import Enhanced Modules
from core.enhanced.keyword_expander import KeywordExpander
from core.enhanced.async_searcher import AsyncSearcher
from core.enhanced.enhanced_processor import EnhancedProcessor

# ==============================================================================
# 0. GLOBAL SESSION MANAGEMENT
# ==============================================================================

class SessionManager:
    """å…¨å±€ä¼šè¯ç®¡ç†å™¨ï¼Œç”¨äºé™åˆ¶å¹¶å‘è®¿é—®äººæ•°"""
    _instance = None
    _lock = threading.Lock()
    _active_sessions = {} # session_id -> last_seen_timestamp
    MAX_USERS = 3
    TIMEOUT_SECONDS = 300 # 5åˆ†é’Ÿæ— æ“ä½œè‡ªåŠ¨é‡Šæ”¾åé¢

    def __new__(cls):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super(SessionManager, cls).__new__(cls)
            return cls._instance

    def update_session(self, session_id):
        with self._lock:
            current_time = time.time()
            # æ¸…ç†è¿‡æœŸä¼šè¯
            self._active_sessions = {
                sid: ts for sid, ts in self._active_sessions.items() 
                if current_time - ts < self.TIMEOUT_SECONDS
            }
            # æ›´æ–°å½“å‰ä¼šè¯
            self._active_sessions[session_id] = current_time

    def get_active_count(self):
        with self._lock:
            current_time = time.time()
            return len([ts for ts in self._active_sessions.values() if current_time - ts < self.TIMEOUT_SECONDS])

    def can_access(self, session_id):
        with self._lock:
            current_time = time.time()
            # æ¸…ç†è¿‡æœŸä¼šè¯
            self._active_sessions = {
                sid: ts for sid, ts in self._active_sessions.items() 
                if current_time - ts < self.TIMEOUT_SECONDS
            }
            # å¦‚æœå·²ç»åœ¨æ´»è·ƒåˆ—è¡¨ä¸­ï¼Œå…è®¸è®¿é—®
            if session_id in self._active_sessions:
                return True
            # å¦‚æœåé¢æœªæ»¡ï¼Œå…è®¸è®¿é—®
            return len(self._active_sessions) < self.MAX_USERS

# ==============================================================================
# 1. INITIALIZATION & UI STYLING
# ==============================================================================

def safe_get_secret(key, default=None):
    """Safely get a secret from Streamlit secrets or return default."""
    try:
        # st.secrets behaves like a dict but can raise exceptions if file is missing
        if key in st.secrets:
            return st.secrets[key]
    except Exception:
        pass
    return default

def apply_custom_styles():
    st.markdown("""
        <style>
        /* Main Container Styling */
        .main {
            background-color: #001f3f; /* æ·±è“è‰²èƒŒæ™¯ */
            color: #FFD700; /* é‡‘è‰²æ–‡å­— */
        }
        
        /* å…¨å±€æ–‡å­—é¢œè‰²è°ƒæ•´ */
        .main p, .main span, .main label, .main h1, .main h2, .main h3, .main div {
            color: #FFD700 !important;
        }

        /* é’ˆå¯¹è¾“å…¥æ¡†çš„æ–‡å­—é¢œè‰²å¾®è°ƒ */
        input {
            color: #000 !important; /* è¾“å…¥å†…å®¹ä¿æŒé»‘è‰²ä»¥ä¾¿é˜…è¯» */
        }

        /* Card-like containers */
        div.stButton > button:first-child {
            background-color: #FFD700; /* é‡‘è‰²æŒ‰é’® */
            color: #001f3f; /* æ·±è“è‰²æ–‡å­— */
            border-radius: 8px;
            padding: 0.5rem 1rem;
            font-weight: 600;
            border: none;
            transition: all 0.3s ease;
        }
        
        div.stButton > button:hover {
            background-color: #e6c200;
            box-shadow: 0 4px 8px rgba(0,0,0,0.3);
        }
        
        /* Sidebar styling */
        section[data-testid="stSidebar"] {
            background-color: #001529;
        }
        
        /* Metric styling */
        [data-testid="stMetricValue"] {
            font-size: 2rem;
            color: #FFD700 !important;
        }
        
        /* Custom Header */
        .header-container {
            padding: 1.5rem;
            background: #001529;
            border-radius: 12px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.5);
            margin-bottom: 2rem;
            text-align: center;
            border: 1px solid #FFD700;
        }
        
        .header-container h1, .header-container p {
            color: #FFD700 !important;
        }
        
        /* Dataframe styling */
        .stDataFrame {
            border: 1px solid #FFD700;
            border-radius: 8px;
            background-color: #001f3f;
        }
        </style>
    """, unsafe_allow_html=True)

def init_environment():
    """Initialize environment variables and directories."""
    load_dotenv()
    os.makedirs("output", exist_ok=True)
    
    # Check for .env file or Streamlit Secrets
    serper_key = os.getenv("SERPER_API_KEY") or safe_get_secret("SERPER_API_KEY")
    zhipu_key = os.getenv("ZHIPUAI_API_KEY") or safe_get_secret("ZHIPUAI_API_KEY")
    
    status = {
        "serper": bool(serper_key),
        "zhipu": bool(zhipu_key),
        "output_dir": os.path.exists("output")
    }
    return status

def check_password():
    """Returns True if the user had the correct password."""
    password_env = os.getenv("APP_PASSWORD") or safe_get_secret("APP_PASSWORD", "admin123")
    
    if not password_env:
        return True # No password required

    def password_entered():
        if st.session_state["password"] == password_env:
            st.session_state["password_correct"] = True
            del st.session_state["password"]
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        st.markdown('<div class="header-container"><h1>æ¬¢è¿æ¥åˆ°superlinkæ•°æ®åº“</h1><p>è¯·è¾“å…¥å¼•æ“è®¿é—®å¯†ç ä»¥ç»§ç»­ã€‚</p></div>', unsafe_allow_html=True)
        st.text_input("å¯†ç ", type="password", on_change=password_entered, key="password")
        return False
    elif not st.session_state["password_correct"]:
        st.text_input("å¯†ç ", type="password", on_change=password_entered, key="password")
        st.error("ğŸ˜• å¯†ç é”™è¯¯")
        return False
    return True

# Page Config
st.set_page_config(
    page_title="SuperLink æ•°æ®å¼•æ“",
    page_icon="ğŸš€",
    layout="wide"
)

apply_custom_styles()

# --- Session Limiter ---
from streamlit.runtime.scriptrunner import get_script_run_ctx
ctx = get_script_run_ctx()
session_id = ctx.session_id if ctx else "default"

manager = SessionManager()
if not manager.can_access(session_id):
    st.error("ğŸš¦ ç³»ç»Ÿç¹å¿™ / System Busy")
    st.warning(f"å½“å‰å·²æœ‰ {manager.get_active_count()} ä½ç”¨æˆ·æ­£åœ¨ä½¿ç”¨ã€‚ä¸ºäº†ä¿è¯æœç´¢æ€§èƒ½ï¼Œè¯·æ’é˜Ÿç­‰å¾…åé¢é‡Šæ”¾ã€‚")
    st.info("ğŸ’¡ æç¤ºï¼šå½“æœ‰å…¶ä»–ç”¨æˆ·å…³é—­é¡µé¢æˆ–è¶…è¿‡ 5 åˆ†é’Ÿæœªæ“ä½œåï¼Œåé¢å°†è‡ªåŠ¨é‡Šæ”¾ã€‚")
    if st.button("åˆ·æ–°é‡è¯•"):
        st.rerun()
    st.stop()

# æ­£å¸¸è®¿é—®åˆ™æ›´æ–°æ´»è·ƒçŠ¶æ€
manager.update_session(session_id)
# -----------------------

# Global State Initialization
if 'init_done' not in st.session_state:
    st.session_state['api_status'] = init_environment()
    st.session_state['init_done'] = True

# Authentication
if not check_password():
    st.stop()

# ==============================================================================
# 2. HELPER FUNCTIONS
# ==============================================================================

def get_output_filename(task_name, keyword, module_name):
    """Generate a unique filename with task name, keyword, module and timestamp."""
    now = datetime.now()
    timestamp = now.strftime("%Y%m%d_%H%M")
    
    # Sanitize inputs
    def sanitize(s):
        return "".join([c for c in s if c.isalnum() or c in (' ', '_', '-')]).strip().replace(' ', '_')
    
    safe_task = sanitize(task_name) or "task"
    safe_keyword = sanitize(keyword) or "none"
    # Get short module name (e.g., "Logistics" from "1. Logistics (USA/EU)")
    safe_module = sanitize(module_name.split('.')[1].split('(')[0]) if '.' in module_name else sanitize(module_name)
    
    return f"output/{safe_task}_{safe_module}_{safe_keyword}_{timestamp}.csv"

def show_preview(file_path):
    if os.path.exists(file_path):
        try:
            df = pd.read_csv(file_path)
            st.success(f"âœ… æ•°æ®å·²åŠ è½½: `{os.path.basename(file_path)}`")
            
            col1, col2 = st.columns([1, 4])
            with col1:
                with open(file_path, "rb") as f:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½ CSV",
                        data=f,
                        file_name=os.path.basename(file_path),
                        mime="text/csv",
                    )
            with col2:
                st.caption(f"å…±æ‰¾åˆ°çº¿ç´¢: **{len(df) - 1}** æ¡ (é¦–è¡Œå…ƒæ•°æ®é™¤å¤–)")
            
            st.dataframe(df.head(100), use_container_width=True)
        except Exception as e:
            st.warning(f"é¢„è§ˆé”™è¯¯: {e}")
    else:
        st.info("æš‚æ— å¯ç”¨æ•°æ®æ–‡ä»¶ã€‚")

def list_history_files():
    files = glob.glob("output/*.csv")
    files.sort(key=os.path.getmtime, reverse=True)
    return files

# ==============================================================================
# 3. DASHBOARD COMPONENTS
# ==============================================================================

async def run_enhanced_task(module_idx, keyword, module_name, output_file):
    """Execute task using the new Enhanced engine (Async + AI Batching)."""
    expander = KeywordExpander()
    searcher = AsyncSearcher(concurrency=3) # Safe for cheap proxy
    processor = EnhancedProcessor()
    
    st.info("ğŸ” æ­£åœ¨æ™ºèƒ½æ‰©å±•å…³é”®è¯ä»¥å®ç°æœ€å¤§è¦†ç›–...")
    module_id = str(module_idx + 1)
    # Expand for major regions
    expanded_queries = expander.expand(keyword, module_id)
    # Target more queries for maximum coverage
    target_queries = expanded_queries[:20] 
    
    st.info(f"ğŸš€ æ­£åœ¨å¯åŠ¨ {len(target_queries)} ä¸ªå­æŸ¥è¯¢çš„å¹¶è¡Œæœç´¢ (æ·±åº¦: 5é¡µ)...")
    raw_results = await searcher.search_batch(target_queries, pages_per_query=5)
    
    if not raw_results:
        st.warning("å¢å¼ºæ¨¡å¼ä¸‹æœªæ‰¾åˆ°ä»»ä½•ç»“æœã€‚")
        return False
        
    st.info(f"ğŸ§  AI æ­£åœ¨åˆ†æ‰¹å¤„ç† {len(raw_results)} æ¡åŸå§‹æ•°æ®...")
    all_leads = processor.process_batch_enhanced(raw_results, batch_size=15)
    
    if all_leads:
        # Save results
        from core.deduplicator import Deduplicator
        dedup = Deduplicator()
        unique_leads = dedup.filter_unique(all_leads)
        
        # Save to CSV with Metadata header
        df = pd.DataFrame(unique_leads)
        
        # Create metadata row
        metadata = pd.DataFrame([{
            "å…¬å¸åç§°": f"ä»»åŠ¡æ¨¡å—: {module_name}",
            "æ³¨å†Œå›½å®¶/åŸå¸‚": f"æ ¸å¿ƒå…³é”®è¯: {keyword}",
            "ä¸šåŠ¡è´Ÿè´£äºº": f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            "å…¬å¼€é‚®ç®±": "---",
            "å…¬å¼€ç”µè¯": "---",
            "ä¸šåŠ¡èŒƒå›´": "---",
            "æ¥æºURL": "---"
        }])
        
        # Combine metadata with data
        final_df = pd.concat([metadata, df], ignore_index=True)
        final_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        st.success(f"âœ¨ å¢å¼ºä»»åŠ¡å®Œæˆï¼å…±æ•è· {len(unique_leads)} æ¡å”¯ä¸€çº¿ç´¢ã€‚")
        return True
    return False

def show_api_status_dashboard():
    with st.sidebar:
        st.markdown("### ğŸ“Š ç³»ç»Ÿä»ªè¡¨ç›˜")
        status = st.session_state.get('api_status', {})
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown(f"**Serper æœç´¢**")
            st.markdown("ğŸŸ¢ æ­£å¸¸" if status.get("serper") else "ğŸ”´ ç¼ºå¤±")
        with col2:
            st.markdown(f"**æ™ºè°± AI**")
            st.markdown("ğŸŸ¢ æ­£å¸¸" if status.get("zhipu") else "ğŸ”´ ç¼ºå¤±")
            
        st.markdown("---")
        st.markdown("### ğŸ› ï¸ è¿è¡Œä¿¡æ¯")
        st.caption(f"å½“å‰ç›®å½•: `{os.getcwd()}`")
        st.caption(f"æœåŠ¡å™¨ç«¯å£: `3000` (æ˜ å°„ä¸­)")

# ==============================================================================
# 4. CORE LOGIC ADAPTERS
# ==============================================================================

def run_single_search(choice_idx, keyword, module_name, output_file):
    """Execute standard single-query search (Options 1-4)."""
    searcher = Searcher()
    processor = Processor()
    
    status_container = st.container()
    with status_container:
        st.info("ğŸš€ æ­£åœ¨å¯åŠ¨æœç´¢å¼•æ“...")
    
    try:
        if choice_idx == 0: results = searcher.search_logistics_usa_europe(keyword)
        elif choice_idx == 1: results = searcher.search_importer_usa_europe(keyword)
        elif choice_idx == 2: results = searcher.search_china_forwarder(keyword)
        elif choice_idx == 3: results = searcher.search_china_exporter(keyword)
        else: results = {}
            
        if not results:
            st.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•ç»“æœã€‚è¯·æ£€æŸ¥å…³é”®è¯æˆ–ä»£ç†è®¾ç½®ã€‚")
            return False

        st.info("ğŸ§  æ™ºè°± AI æ­£åœ¨åˆ†æå¹¶æå–çº¿ç´¢...")
        
        # We need to manually save here to include metadata if needed, 
        # but let's first get the data from processor.
        # Note: process_and_save normally handles saving. 
        # To maintain consistency, we'll let it save and then we can prepend metadata if we want,
        # or better, we modify process_and_save to handle it.
        # For now, let's just use the existing one and I will update processor.py later.
        processor.process_and_save(results, output_file=output_file)
        
        # After saving, let's prepend the metadata line
        if os.path.exists(output_file):
            df = pd.read_csv(output_file)
            metadata = pd.DataFrame([{
                "å…¬å¸åç§°": f"ä»»åŠ¡æ¨¡å—: {module_name}",
                "æ³¨å†Œå›½å®¶/åŸå¸‚": f"æ ¸å¿ƒå…³é”®è¯: {keyword}",
                "ä¸šåŠ¡è´Ÿè´£äºº": f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
                "å…¬å¼€é‚®ç®±": "---",
                "å…¬å¼€ç”µè¯": "---",
                "ä¸šåŠ¡èŒƒå›´": "---",
                "æ¥æºURL": "---"
            }])
            final_df = pd.concat([metadata, df], ignore_index=True)
            final_df.to_csv(output_file, index=False, encoding='utf-8-sig')

        st.success("âœ¨ ä»»åŠ¡æˆåŠŸå®Œæˆï¼")
        return True
    except Exception as e:
        st.error(f"âŒ è¿è¡Œå‡ºé”™: {str(e)}")
        return False

def run_batch_mode(module_choice, base_keyword, output_file, progress_bar):
    searcher = Searcher()
    processor = Processor()
    module_id = str(module_choice + 1)
    
    st.info(f"æ­£åœ¨ä¸ºæ¨¡å— {module_id} æ‰©å±•æŸ¥è¯¢å…³é”®è¯...")
    queries = searcher.expand_keywords(base_keyword, module_id)
    total = len(queries)
    
    for i, query in enumerate(queries):
        progress = (i + 1) / total
        progress_bar.progress(progress, text=f"è¿›åº¦ {i+1}/{total}: {query}")
        try:
            results = searcher._execute_search(query, num_results=20)
            if results and "organic" in results:
                processor.process_and_save(results, output_file=output_file)
            if i < total - 1: time.sleep(2)
        except Exception as e:
            st.error(f"æ‰¹é‡æ¨¡å¼é”™è¯¯ '{query}': {e}")
    return True

def load_progress_log():
    log_file = "progress_log.json"
    if os.path.exists(log_file):
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except: pass
    return {}

def start_automation_thread(keyword, module_choice, output_file):
    module_id = str(module_choice + 1)
    manager = AutomationManager(output_file)
    stop_event = threading.Event()
    
    def target():
        try:
            manager.run_campaign(keyword, module_id, stop_event)
        except Exception as e:
            print(f"Thread Error: {e}")
        finally:
            st.session_state['job_status'] = 'done'
            
    t = threading.Thread(target=target)
    t.start()
    return t, stop_event

# ==============================================================================
# 5. MAIN UI LAYOUT
# ==============================================================================

# Header
st.markdown("""
    <div class="header-container">
        <h1 style='color: #FFD700; margin-bottom: 0;'>æ¬¢è¿æ¥åˆ°superlinkæ•°æ®åº“</h1>
        <p style='color: #FFD700; font-size: 1.1rem;'>ä¸“ä¸šçš„ B2B å•†ä¸šçº¿ç´¢æŒ–æ˜å·¥å‚</p>
    </div>
""", unsafe_allow_html=True)

show_api_status_dashboard()

tab_run, tab_history, tab_settings = st.tabs(["ğŸš€ å¯åŠ¨å¼•æ“", "ğŸ“‚ çº¿ç´¢åº“", "âš™ï¸ ç³»ç»Ÿè®¾ç½®"])

# --- TAB 1: LAUNCH ENGINE ---
with tab_run:
    col_input, col_status = st.columns([1, 2])
    
    with col_input:
        st.markdown("### ğŸ› ï¸ ä»»åŠ¡é…ç½®")
        task_name = st.text_input("ä»»åŠ¡æ ‡è¯†", value="search_leads", help="ç”¨äºç”Ÿæˆå¯¼å‡ºçš„æ–‡ä»¶å")
        module_options = [
            "1. æ¬§ç¾ç‰©æµå•† (Logistics)",
            "2. æ¬§ç¾è¿›å£å•† (Importers)",
            "3. ä¸­å›½è´§ä»£åŒè¡Œ (CN Forwarders)",
            "4. ä¸­å›½å‡ºå£å·¥å‚ (CN Exporters)",
            "5. æ‰¹é‡æ¨¡å¼ (å¤šæŸ¥è¯¢)",
            "6. å·¥å‚æ¨¡å¼ (å…¨è‡ªåŠ¨)"
        ]
        selected_option = st.selectbox("é€‰æ‹©æœç´¢ç­–ç•¥", module_options)
        choice_idx = module_options.index(selected_option)
        
        keyword = st.text_input("ç›®æ ‡å…³é”®è¯", placeholder="ä¾‹å¦‚ï¼šå®¶å…·, ç”µå­äº§å“, çººç»‡å“")
        
        st.markdown("---")
        st.markdown("**ğŸš€ æ€§èƒ½å¢å¼ºæ¨¡å¼**")
        use_enhanced = st.checkbox("å¼€å¯å¢å¼ºæœç´¢", value=False, help="ä½¿ç”¨å¼‚æ­¥æœç´¢å’Œæ™ºèƒ½å…³é”®è¯è£‚å˜ï¼Œå¯æŒ–æ˜å‡º 5-10 å€ä»¥ä¸Šçš„çº¿ç´¢é‡ã€‚")
        
        batch_module_idx = 0
        if choice_idx >= 4:
            st.markdown("---")
            sub_options = ["ç‰©æµå•†", "è¿›å£å•†", "è´§ä»£åŒè¡Œ", "å‡ºå£å·¥å‚"]
            batch_sub_choice = st.selectbox("æ‰¹é‡/å·¥å‚æ¨¡å¼çš„åŸºç¡€é€»è¾‘", sub_options)
            batch_module_idx = sub_options.index(batch_sub_choice)

        st.markdown("<br>", unsafe_allow_html=True)
        start_btn = st.button("ğŸš€ å¼€å§‹æ‰§è¡Œ", type="primary", use_container_width=True)

    with col_status:
        st.markdown("### ğŸ“ˆ å®æ—¶æ‰§è¡ŒçŠ¶æ€")
        if 'job_status' not in st.session_state: st.session_state['job_status'] = 'idle'

        if st.session_state['job_status'] == 'running':
            st.info("ğŸ”„ å¼•æ“æ­£åœ¨åå°æŒ‰åŸå¸‚è½®è¯¢æ‰§è¡Œ...")
            progress_data = load_progress_log()
            completed = progress_data.get("completed_cities", [])
            
            m1, m2 = st.columns(2)
            m1.metric("å·²å®ŒæˆåŸå¸‚", len(completed))
            m2.metric("æœ€åæœç´¢åŸå¸‚", completed[-1] if completed else "æ— ")
            
            if st.button("ğŸ›‘ åœæ­¢å¼•æ“", type="secondary"):
                if st.session_state.get('stop_event'): st.session_state['stop_event'].set()
                st.warning("æ­£åœ¨åˆå§‹åŒ–åœæ­¢ç¨‹åº...")
                if st.session_state.get('automation_thread'): st.session_state['automation_thread'].join(timeout=5)
                st.session_state['job_status'] = 'idle'
                st.rerun()
            
            time.sleep(3)
            st.rerun()

        elif st.session_state['job_status'] == 'done':
            st.success("ğŸ å·¥å‚æ¨¡å¼ä»»åŠ¡å·²æ‰§è¡Œå®Œæ¯•ï¼")
            if st.button("é‡ç½®çŠ¶æ€"):
                st.session_state['job_status'] = 'idle'
                st.rerun()
        
        elif st.session_state['job_status'] == 'idle':
            if start_btn:
                if not keyword:
                    st.error("è¯·è¾“å…¥ç›®æ ‡å…³é”®è¯ã€‚")
                else:
                    try:
                        output_file = get_output_filename(task_name, keyword, selected_option)
                        st.session_state['current_output_file'] = output_file
                        
                        success = False
                        if use_enhanced:
                            import asyncio
                            success = asyncio.run(run_enhanced_task(choice_idx, keyword, selected_option, output_file))
                        elif choice_idx < 4:
                            success = run_single_search(choice_idx, keyword, selected_option, output_file)
                        elif choice_idx == 4:
                            progress_bar = st.progress(0, text="æ­£åœ¨åˆå§‹åŒ–æ‰¹é‡ä»»åŠ¡...")
                            success = run_batch_mode(batch_module_idx, keyword, output_file, progress_bar)
                            progress_bar.empty()
                        elif choice_idx == 5:
                            t, stop_event = start_automation_thread(keyword, batch_module_idx, output_file)
                            st.session_state['automation_thread'] = t
                            st.session_state['stop_event'] = stop_event
                            st.session_state['job_status'] = 'running'
                            st.rerun()
                            
                        if success:
                            st.balloons()
                            show_preview(output_file)
                    except Exception as e:
                        st.error(f"ç³»ç»Ÿè¿è¡Œå‡ºé”™: {e}")
            else:
                st.caption("ç­‰å¾…ä»»åŠ¡å‚æ•°è¾“å…¥...")

# --- TAB 2: LEAD REPOSITORY ---
with tab_history:
    st.header("ğŸ“‚ çº¿ç´¢åº“")
    history_files = list_history_files()
    if not history_files:
        st.info("ç›®å‰è¿˜æ²¡æœ‰é‡‡é›†åˆ°ä»»ä½•çº¿ç´¢ã€‚å¯åŠ¨ä¸€ä¸ªä»»åŠ¡æ¥ç”Ÿæˆ CSV æ–‡ä»¶å§ã€‚")
    else:
        selected_file = st.selectbox("æµè§ˆå†å²è®°å½•", history_files, 
                                     format_func=lambda x: f"ğŸ“ {os.path.basename(x)} | {datetime.fromtimestamp(os.path.getmtime(x)).strftime('%Y-%m-%d %H:%M')}")
        if selected_file:
            st.markdown("---")
            show_preview(selected_file)
            if st.button("ğŸ—‘ï¸ åˆ é™¤é€‰ä¸­æ–‡ä»¶"):
                os.remove(selected_file)
                st.success("æ–‡ä»¶å·²æˆåŠŸåˆ é™¤ã€‚")
                st.rerun()

# --- TAB 3: SYSTEM SETTINGS ---
with tab_settings:
    st.header("âš™ï¸ é…ç½®ç®¡ç†")
    st.write("å½“å‰è¿è¡Œç¯å¢ƒé…ç½®ï¼š")
    
    with st.expander("ğŸ”‘ API å‡­è¯"):
        st.info("è¿™äº›å¯†é’¥æ˜¯ä»æ‚¨çš„ .env æ–‡ä»¶æˆ–äº‘ç«¯é…ç½®ä¸­åŠ è½½çš„ã€‚")
        st.text_input("Serper æœç´¢å¯†é’¥", value=os.getenv("SERPER_API_KEY", "æœªè®¾ç½®"), type="password", disabled=True)
        st.text_input("æ™ºè°± AI å¯†é’¥", value=os.getenv("ZHIPUAI_API_KEY", "æœªè®¾ç½®"), type="password", disabled=True)
        
    with st.expander("ğŸŒ ä»£ç†è®¾ç½®"):
        st.write(f"æ˜¯å¦å¯ç”¨ä»£ç†: `{os.getenv('USE_PROXY', 'True')}`")
        st.write(f"ä»£ç†åœ°å€: `{os.getenv('HTTP_PROXY', 'æœªè®¾ç½®')}`")
        
    st.markdown("---")
    st.caption("v1.2.0 | SuperLink æ•°æ®å¼•æ“ | Robin (SuperLink ç ”å‘å›¢é˜Ÿ)")
