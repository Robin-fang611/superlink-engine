import streamlit as st
import os
import sys
import time
import pandas as pd
import glob
import json
import threading
from datetime import datetime
from dotenv import load_dotenv

# Ensure core modules can be imported
sys.path.append(os.getcwd())

from core.searcher import Searcher
from core.processor import Processor
from core.automation import AutomationManager

# Import Enhanced Modules
from core.enhanced.keyword_expander import KeywordExpander
from core.enhanced.async_searcher import AsyncSearcher
from core.enhanced.enhanced_processor import EnhancedProcessor
from core.enhanced.email_extractor import EmailExtractor
from core.enhanced.person_searcher import PersonSearcher
from core.enhanced.email_guesser import EmailGuesser

# ==============================================================================
# 0. GLOBAL SESSION MANAGEMENT
# ==============================================================================

class SessionManager:
    """å…¨å±€ä¼šè¯ç®¡ç†å™¨ï¼Œç”¨äºé™åˆ¶å¹¶å‘è®¿é—®äººæ•°"""
    _instance = None
    _lock = threading.Lock()
    _active_sessions = {} # session_id -> last_seen_timestamp
    MAX_USERS = 3
    TIMEOUT_SECONDS = 300 # 5åˆ†é’Ÿæ— æ“ä½œè‡ªåŠ¨é‡Šæ”¾åé¢

    def __new__(cls):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super(SessionManager, cls).__new__(cls)
            return cls._instance

    def update_session(self, session_id):
        with self._lock:
            current_time = time.time()
            # æ¸…ç†è¿‡æœŸä¼šè¯
            self._active_sessions = {
                sid: ts for sid, ts in self._active_sessions.items() 
                if current_time - ts < self.TIMEOUT_SECONDS
            }
            # æ›´æ–°å½“å‰ä¼šè¯
            self._active_sessions[session_id] = current_time

    def get_active_count(self):
        with self._lock:
            current_time = time.time()
            return len([ts for ts in self._active_sessions.values() if current_time - ts < self.TIMEOUT_SECONDS])

    def can_access(self, session_id):
        with self._lock:
            current_time = time.time()
            # æ¸…ç†è¿‡æœŸä¼šè¯
            self._active_sessions = {
                sid: ts for sid, ts in self._active_sessions.items() 
                if current_time - ts < self.TIMEOUT_SECONDS
            }
            # å¦‚æœå·²ç»åœ¨æ´»è·ƒåˆ—è¡¨ä¸­ï¼Œå…è®¸è®¿é—®
            if session_id in self._active_sessions:
                return True
            # å¦‚æœåé¢æœªæ»¡ï¼Œå…è®¸è®¿é—®
            return len(self._active_sessions) < self.MAX_USERS

# ==============================================================================
# 1. INITIALIZATION & UI STYLING
# ==============================================================================

def safe_get_secret(key, default=None):
    """Safely get a secret from Streamlit secrets or return default."""
    try:
        # st.secrets behaves like a dict but can raise exceptions if file is missing
        if key in st.secrets:
            return st.secrets[key]
    except Exception:
        pass
    return default

def apply_custom_styles():
    st.markdown("""
        <style>
        /* Main Container Styling */
        .main {
            background-color: #001f3f; /* æ·±è“è‰²èƒŒæ™¯ */
            color: #FFD700; /* é‡‘è‰²æ–‡å­— */
        }
        
        /* å…¨å±€æ–‡å­—é¢œè‰²è°ƒæ•´ */
        .main p, .main span, .main label, .main h1, .main h2, .main h3, .main div {
            color: #FFD700 !important;
        }

        /* é’ˆå¯¹è¾“å…¥æ¡†çš„æ–‡å­—é¢œè‰²å¾®è°ƒ */
        input {
            color: #000 !important; /* è¾“å…¥å†…å®¹ä¿æŒé»‘è‰²ä»¥ä¾¿é˜…è¯» */
        }

        /* Card-like containers */
        div.stButton > button:first-child {
            background-color: #FFD700; /* é‡‘è‰²æŒ‰é’® */
            color: #001f3f; /* æ·±è“è‰²æ–‡å­— */
            border-radius: 8px;
            padding: 0.5rem 1rem;
            font-weight: 600;
            border: none;
            transition: all 0.3s ease;
        }
        
        div.stButton > button:hover {
            background-color: #e6c200;
            box-shadow: 0 4px 8px rgba(0,0,0,0.3);
        }
        
        /* Sidebar styling */
        section[data-testid="stSidebar"] {
            background-color: #001529;
        }
        
        /* Metric styling */
        [data-testid="stMetricValue"] {
            font-size: 2rem;
            color: #FFD700 !important;
        }
        
        /* Custom Header */
        .header-container {
            padding: 1.5rem;
            background: #001529;
            border-radius: 12px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.5);
            margin-bottom: 2rem;
            text-align: center;
            border: 1px solid #FFD700;
        }
        
        .header-container h1, .header-container p {
            color: #FFD700 !important;
        }
        
        /* Dataframe styling */
        .stDataFrame {
            border: 1px solid #FFD700;
            border-radius: 8px;
            background-color: #001f3f;
        }
        </style>
    """, unsafe_allow_html=True)

from core.database import DatabaseHandler
from core.verifier import EmailVerifier
from core.email_sender import EmailSender
from core.feedback_processor import FeedbackProcessor

# ... existing code ...

def init_environment():
    """Initialize environment variables and directories."""
    load_dotenv()
    os.makedirs("output", exist_ok=True)
    os.makedirs("templates", exist_ok=True)
    
    # Check for .env file or Streamlit Secrets
    serper_key = os.getenv("SERPER_API_KEY") or safe_get_secret("SERPER_API_KEY")
    zhipu_key = os.getenv("ZHIPUAI_API_KEY") or safe_get_secret("ZHIPUAI_API_KEY")
    
    # Init DB
    db = DatabaseHandler()
    
    status = {
        "serper": bool(serper_key),
        "zhipu": bool(zhipu_key),
        "output_dir": os.path.exists("output"),
        "db_ok": True
    }
    return status

def check_password():
    """Returns True if the user had the correct password."""
    password_env = os.getenv("APP_PASSWORD") or safe_get_secret("APP_PASSWORD", "admin123")
    
    if not password_env:
        return True # No password required

    def password_entered():
        if st.session_state["password"] == password_env:
            st.session_state["password_correct"] = True
            del st.session_state["password"]
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        st.markdown('<div class="header-container"><h1>æ¬¢è¿æ¥åˆ°superlinkæ•°æ®åº“</h1><p>è¯·è¾“å…¥å¼•æ“è®¿é—®å¯†ç ä»¥ç»§ç»­ã€‚</p></div>', unsafe_allow_html=True)
        st.text_input("å¯†ç ", type="password", on_change=password_entered, key="password")
        return False
    elif not st.session_state["password_correct"]:
        st.text_input("å¯†ç ", type="password", on_change=password_entered, key="password")
        st.error("ğŸ˜• å¯†ç é”™è¯¯")
        return False
    return True

# Page Config
st.set_page_config(
    page_title="SuperLink æ•°æ®å¼•æ“",
    page_icon="ğŸš€",
    layout="wide"
)

apply_custom_styles()

# --- Session Limiter ---
from streamlit.runtime.scriptrunner import get_script_run_ctx
ctx = get_script_run_ctx()
session_id = ctx.session_id if ctx else "default"

manager = SessionManager()
if not manager.can_access(session_id):
    st.error("ğŸš¦ ç³»ç»Ÿç¹å¿™ / System Busy")
    st.warning(f"å½“å‰å·²æœ‰ {manager.get_active_count()} ä½ç”¨æˆ·æ­£åœ¨ä½¿ç”¨ã€‚ä¸ºäº†ä¿è¯æœç´¢æ€§èƒ½ï¼Œè¯·æ’é˜Ÿç­‰å¾…åé¢é‡Šæ”¾ã€‚")
    st.info("ğŸ’¡ æç¤ºï¼šå½“æœ‰å…¶ä»–ç”¨æˆ·å…³é—­é¡µé¢æˆ–è¶…è¿‡ 5 åˆ†é’Ÿæœªæ“ä½œåï¼Œåé¢å°†è‡ªåŠ¨é‡Šæ”¾ã€‚")
    if st.button("åˆ·æ–°é‡è¯•"):
        st.rerun()
    st.stop()

# æ­£å¸¸è®¿é—®åˆ™æ›´æ–°æ´»è·ƒçŠ¶æ€
manager.update_session(session_id)
# -----------------------

# Global State Initialization
if 'init_done' not in st.session_state:
    st.session_state['api_status'] = init_environment()
    st.session_state['init_done'] = True

# Authentication
if not check_password():
    st.stop()

# ==============================================================================
# 2. HELPER FUNCTIONS
# ==============================================================================

def get_output_filename(task_name, keyword, module_name):
    """Generate a unique filename with task name, keyword, module and timestamp."""
    now = datetime.now()
    timestamp = now.strftime("%Y%m%d_%H%M")
    
    # Sanitize inputs
    def sanitize(s):
        return "".join([c for c in s if c.isalnum() or c in (' ', '_', '-')]).strip().replace(' ', '_')
    
    safe_task = sanitize(task_name) or "task"
    safe_keyword = sanitize(keyword) or "none"
    # Get short module name (e.g., "Logistics" from "1. Logistics (USA/EU)")
    safe_module = sanitize(module_name.split('.')[1].split('(')[0]) if '.' in module_name else sanitize(module_name)
    
    return f"output/{safe_task}_{safe_module}_{safe_keyword}_{timestamp}.csv"

def show_preview(file_path):
    if os.path.exists(file_path):
        try:
            df = pd.read_csv(file_path)
            st.success(f"âœ… æ•°æ®å·²åŠ è½½: `{os.path.basename(file_path)}`")
            
            col1, col2 = st.columns([1, 4])
            with col1:
                with open(file_path, "rb") as f:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½ CSV",
                        data=f,
                        file_name=os.path.basename(file_path),
                        mime="text/csv",
                    )
            with col2:
                st.caption(f"å…±æ‰¾åˆ°çº¿ç´¢: **{len(df) - 1}** æ¡ (é¦–è¡Œå…ƒæ•°æ®é™¤å¤–)")
            
            st.dataframe(df.head(100), use_container_width=True)
        except Exception as e:
            st.warning(f"é¢„è§ˆé”™è¯¯: {e}")
    else:
        st.info("æš‚æ— å¯ç”¨æ•°æ®æ–‡ä»¶ã€‚")

def list_history_files():
    files = glob.glob("output/*.csv")
    files.sort(key=os.path.getmtime, reverse=True)
    return files

# ==============================================================================
# 3. DASHBOARD COMPONENTS
# ==============================================================================

async def run_enhanced_task(module_idx, keyword, module_name, output_file, deep_dive=False, target_positions=None):
    """Execute task using the new Enhanced engine (Async + AI Batching + Deep Dive)."""
    expander = KeywordExpander()
    searcher = AsyncSearcher(concurrency=3) # Safe for cheap proxy
    processor = EnhancedProcessor()
    
    st.info("ğŸ” æ­£åœ¨æ™ºèƒ½æ‰©å±•å…³é”®è¯ä»¥å®ç°æœ€å¤§è¦†ç›–...")
    module_id = str(module_idx + 1)
    # Expand for major regions
    expanded_queries = expander.expand(keyword, module_id)
    # Target more queries for maximum coverage
    target_queries = expanded_queries[:20] 
    
    st.info(f"ğŸš€ æ­£åœ¨å¯åŠ¨ {len(target_queries)} ä¸ªå­æŸ¥è¯¢çš„å¹¶è¡Œæœç´¢ (æ·±åº¦: 5é¡µ)...")
    raw_results = await searcher.search_batch(target_queries, pages_per_query=5)
    
    if not raw_results:
        st.warning("å¢å¼ºæ¨¡å¼ä¸‹æœªæ‰¾åˆ°ä»»ä½•ç»“æœã€‚")
        return False
        
    st.info(f"ğŸ§  AI æ­£åœ¨åˆ†æ‰¹å¤„ç† {len(raw_results)} æ¡åŸå§‹æ•°æ®...")
    all_leads = processor.process_batch_enhanced(raw_results, batch_size=15)
    
    if not all_leads:
        st.warning("AI å¤„ç†åæœªæå–åˆ°æœ‰æ•ˆçº¿ç´¢ã€‚")
        return False

    # --- DEEP DIVE LOGIC ---
    if deep_dive:
        st.info("ğŸ¯ æ­£åœ¨æ‰§è¡Œè”ç³»äººæ·±æŒ– (Deep Dive)...")
        extractor = EmailExtractor()
        person_searcher = PersonSearcher()
        guesser = EmailGuesser()
        
        progress_text = "æ­£åœ¨æ·±æŒ–è”ç³»äººä¿¡æ¯..."
        dive_progress = st.progress(0, text=progress_text)
        
        for i, lead in enumerate(all_leads):
            dive_progress.progress((i + 1) / len(all_leads), text=f"æ·±æŒ–ä¸­ ({i+1}/{len(all_leads)}): {lead.get('å…¬å¸åç§°')}")
            
            # 1. å®˜ç½‘é‚®ç®±æ·±æŒ–
            url = lead.get('æ¥æºURL')
            if url and url.startswith("http"):
                found_emails = extractor.extract_from_website(url)
                if found_emails:
                    current_email = lead.get('å…¬å¼€é‚®ç®±')
                    if not current_email or current_email in ["n/a", "none", ""]:
                        lead['å…¬å¼€é‚®ç®±'] = found_emails[0]
                    # è®°å½•é¢å¤–å‘ç°çš„é‚®ç®±
                    lead['å¤‡ç”¨é‚®ç®±'] = ", ".join(found_emails[1:3])
            
            # 2. LinkedIn å…³é”®å†³ç­–äººæ·±æŒ–
            company = lead.get('å…¬å¸åç§°')
            if company:
                makers = person_searcher.find_decision_makers(company, target_positions)
                if makers:
                    # å°è¯•ä¸ºç¬¬ä¸€ä½å†³ç­–äººçŒœæµ‹é‚®ç®±
                    domain = urlparse(url).netloc if url else ""
                    if domain:
                        p_emails = guesser.guess_and_verify(makers[0]['name'], domain)
                        if p_emails:
                            makers[0]['email'] = p_emails[0]
                    
                    # æ ¼å¼åŒ–å­˜å…¥çº¿ç´¢åº“
                    maker_info = []
                    for m in makers[:2]: # åªå–å‰ä¸¤ä½
                        info = f"{m['name']} ({m['position']})"
                        if m.get('email'): info += f" - {m['email']}"
                        maker_info.append(info)
                    lead['å…³é”®å†³ç­–äºº'] = " | ".join(maker_info)
        
        dive_progress.empty()
    # -----------------------

    # Save results
    from core.deduplicator import Deduplicator
    dedup = Deduplicator()
    unique_leads = dedup.filter_unique(all_leads)
    
    if unique_leads:
        # Save to CSV with Metadata header
        df = pd.DataFrame(unique_leads)
        
        # Create metadata row
        metadata = pd.DataFrame([{
            "å…¬å¸åç§°": f"ä»»åŠ¡æ¨¡å—: {module_name}",
            "æ³¨å†Œå›½å®¶/åŸå¸‚": f"æ ¸å¿ƒå…³é”®è¯: {keyword}",
            "ä¸šåŠ¡è´Ÿè´£äºº": f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            "å…¬å¼€é‚®ç®±": "---",
            "å…¬å¼€ç”µè¯": "---",
            "ä¸šåŠ¡èŒƒå›´": "---",
            "æ¥æºURL": "---"
        }])
        
        # Combine metadata with data
        final_df = pd.concat([metadata, df], ignore_index=True)
        final_df.to_csv(output_file, index=False, encoding='utf-8-sig')
        
        st.success(f"âœ¨ å¢å¼ºä»»åŠ¡å®Œæˆï¼å…±æ•è· {len(unique_leads)} æ¡å”¯ä¸€çº¿ç´¢ã€‚")
        return True
    return False

def show_api_status_dashboard():
    with st.sidebar:
        st.markdown("### ğŸ“Š ç³»ç»Ÿä»ªè¡¨ç›˜")
        status = st.session_state.get('api_status', {})
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown(f"**Serper æœç´¢**")
            st.markdown("ğŸŸ¢ æ­£å¸¸" if status.get("serper") else "ğŸ”´ ç¼ºå¤±")
        with col2:
            st.markdown(f"**æ™ºè°± AI**")
            st.markdown("ğŸŸ¢ æ­£å¸¸" if status.get("zhipu") else "ğŸ”´ ç¼ºå¤±")
            
        st.markdown("---")
        st.markdown("### ğŸ› ï¸ è¿è¡Œä¿¡æ¯")
        st.caption(f"å½“å‰ç›®å½•: `{os.getcwd()}`")
        st.caption(f"æœåŠ¡å™¨ç«¯å£: `3000` (æ˜ å°„ä¸­)")

# ==============================================================================
# 4. CORE LOGIC ADAPTERS
# ==============================================================================

def run_single_search(choice_idx, keyword, module_name, output_file):
    """Execute standard single-query search (Options 1-4)."""
    searcher = Searcher()
    processor = Processor()
    
    status_container = st.container()
    with status_container:
        st.info("ğŸš€ æ­£åœ¨å¯åŠ¨æœç´¢å¼•æ“...")
    
    try:
        if choice_idx == 0: results = searcher.search_logistics_usa_europe(keyword)
        elif choice_idx == 1: results = searcher.search_importer_usa_europe(keyword)
        elif choice_idx == 2: results = searcher.search_china_forwarder(keyword)
        elif choice_idx == 3: results = searcher.search_china_exporter(keyword)
        else: results = {}
            
        if not results:
            st.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•ç»“æœã€‚è¯·æ£€æŸ¥å…³é”®è¯æˆ–ä»£ç†è®¾ç½®ã€‚")
            return False

        st.info("ğŸ§  æ™ºè°± AI æ­£åœ¨åˆ†æå¹¶æå–çº¿ç´¢...")
        
        # We need to manually save here to include metadata if needed, 
        # but let's first get the data from processor.
        # Note: process_and_save normally handles saving. 
        # To maintain consistency, we'll let it save and then we can prepend metadata if we want,
        # or better, we modify process_and_save to handle it.
        # For now, let's just use the existing one and I will update processor.py later.
        processor.process_and_save(results, output_file=output_file)
        
        # After saving, let's prepend the metadata line
        if os.path.exists(output_file):
            df = pd.read_csv(output_file)
            metadata = pd.DataFrame([{
                "å…¬å¸åç§°": f"ä»»åŠ¡æ¨¡å—: {module_name}",
                "æ³¨å†Œå›½å®¶/åŸå¸‚": f"æ ¸å¿ƒå…³é”®è¯: {keyword}",
                "ä¸šåŠ¡è´Ÿè´£äºº": f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
                "å…¬å¼€é‚®ç®±": "---",
                "å…¬å¼€ç”µè¯": "---",
                "ä¸šåŠ¡èŒƒå›´": "---",
                "æ¥æºURL": "---"
            }])
            final_df = pd.concat([metadata, df], ignore_index=True)
            final_df.to_csv(output_file, index=False, encoding='utf-8-sig')

        st.success("âœ¨ ä»»åŠ¡æˆåŠŸå®Œæˆï¼")
        return True
    except Exception as e:
        st.error(f"âŒ è¿è¡Œå‡ºé”™: {str(e)}")
        return False

def run_batch_mode(module_choice, base_keyword, output_file, progress_bar):
    searcher = Searcher()
    processor = Processor()
    module_id = str(module_choice + 1)
    
    st.info(f"æ­£åœ¨ä¸ºæ¨¡å— {module_id} æ‰©å±•æŸ¥è¯¢å…³é”®è¯...")
    queries = searcher.expand_keywords(base_keyword, module_id)
    total = len(queries)
    
    for i, query in enumerate(queries):
        progress = (i + 1) / total
        progress_bar.progress(progress, text=f"è¿›åº¦ {i+1}/{total}: {query}")
        try:
            results = searcher._execute_search(query, num_results=20)
            if results and "organic" in results:
                processor.process_and_save(results, output_file=output_file)
            if i < total - 1: time.sleep(2)
        except Exception as e:
            st.error(f"æ‰¹é‡æ¨¡å¼é”™è¯¯ '{query}': {e}")
    return True

def load_progress_log():
    log_file = "progress_log.json"
    if os.path.exists(log_file):
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except: pass
    return {}

def start_automation_thread(keyword, module_choice, output_file):
    module_id = str(module_choice + 1)
    manager = AutomationManager(output_file)
    stop_event = threading.Event()
    
    def target():
        try:
            manager.run_campaign(keyword, module_id, stop_event)
        except Exception as e:
            print(f"Thread Error: {e}")
        finally:
            st.session_state['job_status'] = 'done'
            
    t = threading.Thread(target=target)
    t.start()
    return t, stop_event

# ==============================================================================
# 5. MAIN UI LAYOUT
# ==============================================================================

# Header
st.markdown("""
    <div class="header-container">
        <h1 style='color: #FFD700; margin-bottom: 0;'>æ¬¢è¿æ¥åˆ°superlinkæ•°æ®åº“</h1>
        <p style='color: #FFD700; font-size: 1.1rem;'>ä¸“ä¸šçš„ B2B å•†ä¸šçº¿ç´¢æŒ–æ˜å·¥å‚</p>
    </div>
""", unsafe_allow_html=True)

show_api_status_dashboard()

tab_run, tab_history, tab_marketing, tab_feedback, tab_settings = st.tabs(["ğŸš€ å¯åŠ¨å¼•æ“", "ğŸ“‚ çº¿ç´¢åº“", "ğŸ“§ è‡ªåŠ¨è¥é”€", "ğŸ“Š åé¦ˆæ€»ç»“", "âš™ï¸ ç³»ç»Ÿè®¾ç½®"])

# --- TAB 1: LAUNCH ENGINE ---
with tab_run:
    col_input, col_status = st.columns([1, 2])
    
    with col_input:
        st.markdown("### ğŸ› ï¸ ä»»åŠ¡é…ç½®")
        task_name = st.text_input("ä»»åŠ¡æ ‡è¯†", value="search_leads", help="ç”¨äºç”Ÿæˆå¯¼å‡ºçš„æ–‡ä»¶å")
        module_options = [
            "1. æ¬§ç¾ç‰©æµå•† (Logistics)",
            "2. æ¬§ç¾è¿›å£å•† (Importers)",
            "3. ä¸­å›½è´§ä»£åŒè¡Œ (CN Forwarders)",
            "4. ä¸­å›½å‡ºå£å·¥å‚ (CN Exporters)",
            "5. æ‰¹é‡æ¨¡å¼ (å¤šæŸ¥è¯¢)",
            "6. å·¥å‚æ¨¡å¼ (å…¨è‡ªåŠ¨)"
        ]
        selected_option = st.selectbox("é€‰æ‹©æœç´¢ç­–ç•¥", module_options)
        choice_idx = module_options.index(selected_option)
        
        keyword = st.text_input("ç›®æ ‡å…³é”®è¯", placeholder="ä¾‹å¦‚ï¼šå®¶å…·, ç”µå­äº§å“, çººç»‡å“")
        
        st.markdown("---")
        st.markdown("**ğŸš€ æ€§èƒ½å¢å¼ºæ¨¡å¼**")
        use_enhanced = st.checkbox("å¼€å¯å¢å¼ºæœç´¢", value=False, help="ä½¿ç”¨å¼‚æ­¥æœç´¢å’Œæ™ºèƒ½å…³é”®è¯è£‚å˜ï¼Œå¯æŒ–æ˜å‡º 5-10 å€ä»¥ä¸Šçš„çº¿ç´¢é‡ã€‚")
        
        st.markdown("**ğŸ¯ è”ç³»äººæ·±æŒ– (Deep Dive)**")
        deep_contacts = st.checkbox("æ·±åº¦æŒ–æ˜å…³é”®äºº", value=False, help="å¼€å¯åï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æŒ–æ˜ LinkedIn å…³é”®äººå¹¶å°è¯•è·å–å…¶ä¸ªäººé‚®ç®±ã€‚")
        target_positions = st.multiselect(
            "ç›®æ ‡èŒä½",
            ["Purchasing", "Logistics", "Procurement", "CEO", "Founder", "Owner", "Manager"],
            default=["Purchasing", "Logistics"]
        )
        
        batch_module_idx = 0
        if choice_idx >= 4:
            st.markdown("---")
            sub_options = ["ç‰©æµå•†", "è¿›å£å•†", "è´§ä»£åŒè¡Œ", "å‡ºå£å·¥å‚"]
            batch_sub_choice = st.selectbox("æ‰¹é‡/å·¥å‚æ¨¡å¼çš„åŸºç¡€é€»è¾‘", sub_options)
            batch_module_idx = sub_options.index(batch_sub_choice)

        st.markdown("<br>", unsafe_allow_html=True)
        start_btn = st.button("ğŸš€ å¼€å§‹æ‰§è¡Œ", type="primary", use_container_width=True)

    with col_status:
        st.markdown("### ğŸ“ˆ å®æ—¶æ‰§è¡ŒçŠ¶æ€")
        if 'job_status' not in st.session_state: st.session_state['job_status'] = 'idle'

        if st.session_state['job_status'] == 'running':
            st.info("ğŸ”„ å¼•æ“æ­£åœ¨åå°æŒ‰åŸå¸‚è½®è¯¢æ‰§è¡Œ...")
            progress_data = load_progress_log()
            completed = progress_data.get("completed_cities", [])
            
            m1, m2 = st.columns(2)
            m1.metric("å·²å®ŒæˆåŸå¸‚", len(completed))
            m2.metric("æœ€åæœç´¢åŸå¸‚", completed[-1] if completed else "æ— ")
            
            if st.button("ğŸ›‘ åœæ­¢å¼•æ“", type="secondary"):
                if st.session_state.get('stop_event'): st.session_state['stop_event'].set()
                st.warning("æ­£åœ¨åˆå§‹åŒ–åœæ­¢ç¨‹åº...")
                if st.session_state.get('automation_thread'): st.session_state['automation_thread'].join(timeout=5)
                st.session_state['job_status'] = 'idle'
                st.rerun()
            
            time.sleep(3)
            st.rerun()

        elif st.session_state['job_status'] == 'done':
            st.success("ğŸ å·¥å‚æ¨¡å¼ä»»åŠ¡å·²æ‰§è¡Œå®Œæ¯•ï¼")
            if st.button("é‡ç½®çŠ¶æ€"):
                st.session_state['job_status'] = 'idle'
                st.rerun()
        
        elif st.session_state['job_status'] == 'idle':
            if start_btn:
                if not keyword:
                    st.error("è¯·è¾“å…¥ç›®æ ‡å…³é”®è¯ã€‚")
                else:
                    try:
                        output_file = get_output_filename(task_name, keyword, selected_option)
                        st.session_state['current_output_file'] = output_file
                        
                        success = False
                        if use_enhanced:
                            import asyncio
                            success = asyncio.run(run_enhanced_task(
                                choice_idx, 
                                keyword, 
                                selected_option, 
                                output_file, 
                                deep_dive=deep_contacts, 
                                target_positions=target_positions
                            ))
                        elif choice_idx < 4:
                            success = run_single_search(choice_idx, keyword, selected_option, output_file)
                        elif choice_idx == 4:
                            progress_bar = st.progress(0, text="æ­£åœ¨åˆå§‹åŒ–æ‰¹é‡ä»»åŠ¡...")
                            success = run_batch_mode(batch_module_idx, keyword, output_file, progress_bar)
                            progress_bar.empty()
                        elif choice_idx == 5:
                            t, stop_event = start_automation_thread(keyword, batch_module_idx, output_file)
                            st.session_state['automation_thread'] = t
                            st.session_state['stop_event'] = stop_event
                            st.session_state['job_status'] = 'running'
                            st.rerun()
                            
                        if success:
                            st.balloons()
                            show_preview(output_file)
                    except Exception as e:
                        st.error(f"ç³»ç»Ÿè¿è¡Œå‡ºé”™: {e}")
            else:
                st.caption("ç­‰å¾…ä»»åŠ¡å‚æ•°è¾“å…¥...")

# --- TAB 2: LEAD REPOSITORY ---
with tab_history:
    st.header("ğŸ“‚ çº¿ç´¢åº“")
    history_files = list_history_files()
    if not history_files:
        st.info("ç›®å‰è¿˜æ²¡æœ‰é‡‡é›†åˆ°ä»»ä½•çº¿ç´¢ã€‚å¯åŠ¨ä¸€ä¸ªä»»åŠ¡æ¥ç”Ÿæˆ CSV æ–‡ä»¶å§ã€‚")
    else:
        selected_file = st.selectbox("æµè§ˆå†å²è®°å½•", history_files, 
                                     format_func=lambda x: f"ğŸ“ {os.path.basename(x)} | {datetime.fromtimestamp(os.path.getmtime(x)).strftime('%Y-%m-%d %H:%M')}")
        if selected_file:
            st.markdown("---")
            show_preview(selected_file)
            if st.button("ğŸ—‘ï¸ åˆ é™¤é€‰ä¸­æ–‡ä»¶"):
                os.remove(selected_file)
                st.success("æ–‡ä»¶å·²æˆåŠŸåˆ é™¤ã€‚")
                st.rerun()

# --- TAB 3: AUTOMATED MARKETING ---
with tab_marketing:
    st.header("ğŸ“§ è‡ªåŠ¨åŒ–é‚®ä»¶è¥é”€")
    db = DatabaseHandler()
    
    col_stat1, col_stat2, col_stat3 = st.columns(3)
    with col_stat1:
        try:
            with db.get_connection() as conn:
                count = conn.execute("SELECT COUNT(*) FROM verified_leads WHERE verification_status='valid'").fetchone()[0]
        except:
            count = 0
        st.metric("å¾…è¥é”€æœ‰æ•ˆçº¿ç´¢", count)
    
    st.markdown("### ğŸ› ï¸ è¥é”€ä»»åŠ¡é…ç½®")
    outreach_subject = st.text_input("é‚®ä»¶ä¸»é¢˜æ¨¡æ¿", value="Partnership Opportunity for {company_name}")
    template_files = glob.glob("templates/*.html")
    selected_tpl = st.selectbox("é€‰æ‹©é‚®ä»¶æ¨¡æ¿", [os.path.basename(f) for f in template_files] if template_files else ["default.html"])
    
    rate_limit = st.slider("å‘é€é—´éš” (ç§’)", 1, 10, 3)
    
    if st.button("ğŸš€ å¼€å§‹æ‰¹é‡ç¾¤å‘", type="primary"):
        import sqlite3
        with db.get_connection() as conn:
            conn.row_factory = sqlite3.Row
            try:
                leads = conn.execute("SELECT * FROM verified_leads WHERE verification_status='valid'").fetchall()
                leads_dict = [dict(row) for row in leads]
            except:
                leads_dict = []
            
        if not leads_dict:
            st.warning("ç›®å‰æ²¡æœ‰éªŒè¯æˆåŠŸçš„æœ‰æ•ˆçº¿ç´¢ã€‚")
        else:
            sender = EmailSender()
            progress_bar = st.progress(0, text="æ­£åœ¨å‘é€...")
            for i, lead in enumerate(leads_dict):
                success, msg = sender.send_email(
                    lead['email'], 
                    outreach_subject.format(company_name=lead['company_name']),
                    selected_tpl,
                    {"company_name": lead['company_name'], "contact_person": lead['contact_person'] or "Partner", "business_scope": lead['business_scope']}
                )
                db.log_email_sent(lead['id'], lead['email'], outreach_subject, selected_tpl, 'sent' if success else 'failed', msg)
                progress_bar.progress((i+1)/len(leads_dict), text=f"è¿›åº¦: {i+1}/{len(leads_dict)} - {lead['email']}")
                time.sleep(rate_limit)
            st.success("æ‰¹é‡è¥é”€ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼")

# --- TAB 4: FEEDBACK ANALYSIS ---
with tab_feedback:
    st.header("ğŸ“Š è¥é”€æ•ˆæœä¸åé¦ˆåˆ†æ")
    
    if st.button("ğŸ“¥ åŒæ­¥æœ€æ–°åé¦ˆ"):
        with st.spinner("æ­£åœ¨è¿æ¥é‚®ç®±è·å–å›å¤..."):
            processor = FeedbackProcessor()
            replies, msg = processor.fetch_latest_replies()
            if replies:
                db = DatabaseHandler()
                for reply in replies:
                    analysis = processor.analyze_intent(reply['body'])
                    reply['category'] = analysis.get('category')
                    reply['analysis'] = analysis.get('reason')
                    db.add_feedback(reply)
                st.success(f"æˆåŠŸåŒæ­¥ {len(replies)} æ¡æ–°åé¦ˆï¼")
            else:
                st.info(f"æš‚æ— æ–°å›å¤: {msg}")

    db = DatabaseHandler()
    try:
        with db.get_connection() as conn:
            df_feedback = pd.read_sql_query("SELECT sender_email, subject, intent_category, received_at FROM feedback_records ORDER BY received_at DESC", conn)
    except:
        df_feedback = pd.DataFrame()
    
    if not df_feedback.empty:
        st.markdown("### ğŸ“© å®¢æˆ·æ„å‘æ¦‚è§ˆ")
        # ç®€å•ç»Ÿè®¡å›¾
        intent_counts = df_feedback['intent_category'].value_counts()
        st.bar_chart(intent_counts)
        
        st.dataframe(df_feedback, use_container_width=True)
    else:
        st.info("å°šæ— åé¦ˆè®°å½•ã€‚")

# --- TAB 5: SYSTEM SETTINGS ---
with tab_settings:
    st.header("âš™ï¸ é…ç½®ç®¡ç†")
    st.write("å½“å‰è¿è¡Œç¯å¢ƒé…ç½®ï¼š")
    
    with st.expander("ğŸ”‘ API å‡­è¯"):
        st.info("è¿™äº›å¯†é’¥æ˜¯ä»æ‚¨çš„ .env æ–‡ä»¶æˆ–äº‘ç«¯é…ç½®ä¸­åŠ è½½çš„ã€‚")
        st.text_input("Serper æœç´¢å¯†é’¥", value=os.getenv("SERPER_API_KEY", "æœªè®¾ç½®"), type="password", disabled=True)
        st.text_input("æ™ºè°± AI å¯†é’¥", value=os.getenv("ZHIPUAI_API_KEY", "æœªè®¾ç½®"), type="password", disabled=True)
        
    with st.expander("ğŸŒ ä»£ç†è®¾ç½®"):
        st.write(f"æ˜¯å¦å¯ç”¨ä»£ç†: `{os.getenv('USE_PROXY', 'True')}`")
        st.write(f"ä»£ç†åœ°å€: `{os.getenv('HTTP_PROXY', 'æœªè®¾ç½®')}`")
        
    with st.expander("ğŸ“§ é‚®ä»¶æœåŠ¡å™¨è®¾ç½®"):
        st.info("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ä»¥ä¸‹å‚æ•°ä»¥å¯ç”¨è¥é”€åŠŸèƒ½ã€‚")
        st.text_input("å‘ä»¶äººé‚®ç®±", value=os.getenv("SENDER_EMAIL", "æœªè®¾ç½®"), disabled=True)
        st.text_input("SMTP æœåŠ¡å™¨", value=os.getenv("SMTP_SERVER", "æœªè®¾ç½®"), disabled=True)
        st.text_input("IMAP æœåŠ¡å™¨", value=os.getenv("IMAP_SERVER", "æœªè®¾ç½®"), disabled=True)
        
    st.markdown("---")
    st.caption("v1.2.0 | SuperLink æ•°æ®å¼•æ“ | Robin (SuperLink ç ”å‘å›¢é˜Ÿ)")
